#!/usr/bin/env python3
"""
arXiv Research Workbench - User-Friendly Interface
ç›´æ„Ÿçš„ã§ä½¿ã„ã‚„ã™ã„è«–æ–‡æ¤œç´¢ãƒ»ç®¡ç†UI
"""
import streamlit as st
import pandas as pd
import subprocess
import time
import os
from datetime import datetime
from pathlib import Path
import json

# Page config
st.set_page_config(
    page_title="arXiv Research Workbench",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Clean, readable CSS
st.markdown("""
<style>
    /* Clean theme with good readability */
    .stApp {
        background-color: #fafafa;
    }
    
    /* Consistent font */
    * {
        font-family: 'Segoe UI', 'Arial', sans-serif !important;
    }
    
    /* Headers */
    h1, h2, h3 {
        color: #1f2937 !important;
        font-weight: 600;
    }
    
    /* Section cards */
    .section-card {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        border: 1px solid #e5e7eb;
        margin: 1rem 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    
    /* Input styling */
    .stTextInput > div > div > input {
        border: 1px solid #d1d5db;
        border-radius: 6px;
        padding: 8px 12px;
        font-size: 14px;
    }
    
    /* Button styling */
    .stButton > button {
        border-radius: 6px;
        font-weight: 500;
        font-size: 14px;
        padding: 8px 16px;
        min-height: 40px;
    }
    
    /* Primary button */
    .stButton > button[kind="primary"] {
        background-color: #2563eb;
        color: white;
        border: none;
    }
    
    .stButton > button[kind="primary"]:hover {
        background-color: #1d4ed8;
    }
    
    /* Success button */
    .success-button > button {
        background-color: #059669 !important;
        color: white !important;
        border: none !important;
    }
    
    /* Warning button */
    .warning-button > button {
        background-color: #d97706 !important;
        color: white !important;
        border: none !important;
    }
    
    /* Info boxes */
    .info-box {
        background-color: #eff6ff;
        border-left: 4px solid #2563eb;
        padding: 12px 16px;
        border-radius: 4px;
        margin: 8px 0;
    }
    
    .success-box {
        background-color: #f0fdf4;
        border-left: 4px solid #059669;
        padding: 12px 16px;
        border-radius: 4px;
        margin: 8px 0;
        color: #065f46;
    }
    
    .error-box {
        background-color: #fef2f2;
        border-left: 4px solid #dc2626;
        padding: 12px 16px;
        border-radius: 4px;
        margin: 8px 0;
        color: #991b1b;
    }
    
    /* Tables */
    .dataframe {
        font-size: 14px !important;
    }
    
    /* Progress indicators */
    .progress-text {
        font-family: 'Consolas', monospace;
        background: #f3f4f6;
        padding: 8px;
        border-radius: 4px;
        font-size: 12px;
    }
    
    /* Remove default margins */
    .block-container {
        padding-top: 2rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'last_results' not in st.session_state:
    st.session_state.last_results = []

class WorkbenchController:
    """Main controller for workbench operations"""
    
    @staticmethod
    def execute_search(query, mode='moderate', limit=10, skip_analyzed=True):
        """Execute search with user-friendly feedback"""
        if not query.strip():
            st.error("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return False
        
        # Build command
        cmd = f"python cli_app.py search \"{query}\" --depth {mode} --papers {limit}"
        if skip_analyzed:
            cmd += " --skip-analyzed"
        
        # Execute with enhanced progress tracking
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        log_placeholder = st.empty()
        
        # Show initial status
        status_placeholder.info(f"ğŸš€ æ¤œç´¢é–‹å§‹: {query}")
        progress_bar = progress_placeholder.progress(0)
        
        try:
            # Start the process
            import time
            start_time = time.time()
            
            with st.spinner(f"'{query}'ã‚’æ¤œç´¢ãƒ»åˆ†æä¸­..."):
                # Show command for transparency
                with st.expander("å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰"):
                    st.code(cmd, language="bash")
                
                # Simulate progress updates during execution
                result = subprocess.run(
                    cmd, shell=True, capture_output=True, 
                    text=True, timeout=300  # 5 minute timeout
                )
                
                # Update progress to completion
                progress_bar.progress(100)
                elapsed_time = int(time.time() - start_time)
                
                if result.returncode == 0:
                    status_placeholder.success(f"âœ… æ¤œç´¢å®Œäº†: '{query}' ({elapsed_time}ç§’)")
                    
                    # Show results summary
                    if result.stdout:
                        # Extract useful info from stdout
                        lines = result.stdout.split('\n')
                        found_papers = [line for line in lines if 'Found' in line or 'ç™ºè¦‹' in line]
                        analyzed_papers = [line for line in lines if 'Analyzed' in line or 'åˆ†æ' in line]
                        
                        summary_info = []
                        if found_papers:
                            summary_info.extend(found_papers[-2:])  # Last 2 found messages
                        if analyzed_papers:
                            summary_info.extend(analyzed_papers[-2:])  # Last 2 analysis messages
                        
                        if summary_info:
                            st.info("ğŸ“Š " + " | ".join(summary_info))
                        
                        with st.expander("ğŸ“‹ è©³ç´°ãƒ­ã‚°"):
                            st.text(result.stdout)
                    
                    return True
                else:
                    st.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼")
                    
                    # Show detailed error information
                    if result.stderr:
                        error_msg = result.stderr
                        if "No papers found" in error_msg:
                            st.warning("ğŸ“­ æŒ‡å®šã—ãŸæ¤œç´¢æ¡ä»¶ã§ã¯è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                            st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè‹±èªæ¨å¥¨ï¼‰ã§è©¦ã—ã¦ãã ã•ã„")
                        elif "timeout" in error_msg.lower():
                            st.warning("â±ï¸ å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
                            st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: è«–æ–‡æ•°ã‚’æ¸›ã‚‰ã™ã‹ã€shallowãƒ¢ãƒ¼ãƒ‰ã§è©¦ã—ã¦ãã ã•ã„")
                        else:
                            with st.expander("ğŸ” è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                                st.text(error_msg)
                    
                    return False
                    
        except subprocess.TimeoutExpired:
            st.error("â±ï¸ å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ5åˆ†åˆ¶é™ï¼‰")
            return False
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    @staticmethod
    def export_database(filename=None):
        """Export database with feedback"""
        # Generate unique filename with timestamp
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"export_{timestamp}.xlsx"
        
        if not filename.endswith('.xlsx'):
            filename += '.xlsx'
        
        # Create exports directory if it doesn't exist
        export_dir = Path("exports")
        export_dir.mkdir(exist_ok=True)
        filepath = export_dir / filename
        
        cmd = f"python cli_app.py registry export --output {filepath}"
        
        with st.spinner("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
            try:
                result = subprocess.run(
                    cmd, shell=True, capture_output=True, text=True, timeout=30
                )
                
                if result.returncode == 0:
                    if filepath.exists():
                        st.success(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {filepath.name}")
                        # Return full path for download
                        return str(filepath)
                    else:
                        st.warning("âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        st.info(f"æœŸå¾…ã•ã‚ŒãŸãƒ‘ã‚¹: {filepath}")
                        return None
                else:
                    st.error("âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼")
                    if result.stderr:
                        # More specific error handling
                        if "Permission denied" in result.stderr:
                            st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‹ã‹ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        else:
                            st.text(result.stderr)
                    return None
                    
            except subprocess.TimeoutExpired:
                st.error("â±ï¸ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ30ç§’ï¼‰")
                return None
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return None
    
    @staticmethod
    def translate_paper(arxiv_id):
        """Translate paper with feedback"""
        if not arxiv_id.strip():
            st.error("arXiv IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return False
        
        # Convert arXiv ID to PDF URL if needed
        if not arxiv_id.startswith('http'):
            pdf_url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
        else:
            pdf_url = arxiv_id
        
        cmd = f"python cli_app.py translate \"{pdf_url}\" --academic"
        
        # Enhanced translation progress
        translation_placeholder = st.empty()
        translation_status = st.empty()
        
        translation_status.info(f"ğŸŒ ç¿»è¨³é–‹å§‹: {arxiv_id}")
        progress_bar = translation_placeholder.progress(0)
        
        with st.spinner(f"{arxiv_id}ã‚’ç¿»è¨³ä¸­..."):
            start_time = time.time()
            
            try:
                # Show estimated time
                st.info("â±ï¸ äºˆæƒ³å‡¦ç†æ™‚é–“: 2-3åˆ†")
                
                result = subprocess.run(
                    cmd, shell=True, capture_output=True, 
                    text=True, timeout=180  # 3 minute timeout
                )
                
                progress_bar.progress(100)
                elapsed_time = int(time.time() - start_time)
                
                if result.returncode == 0:
                    translation_status.success(f"âœ… ç¿»è¨³å®Œäº†: {arxiv_id} ({elapsed_time}ç§’)")
                    
                    # Save translation
                    translations_dir = Path("translations")
                    translations_dir.mkdir(exist_ok=True)
                    
                    safe_filename = arxiv_id.replace('/', '_').replace(':', '_').replace('?', '_')
                    output_path = translations_dir / f"{safe_filename}.html"
                    
                    with open(output_path, 'w', encoding='utf-8') as f:
                        f.write(result.stdout)
                    
                    st.info(f"ğŸ’¾ ä¿å­˜å…ˆ: {output_path}")
                    return True
                else:
                    st.error("âŒ ç¿»è¨³ã‚¨ãƒ©ãƒ¼")
                    st.text(result.stderr)
                    return False
                    
            except subprocess.TimeoutExpired:
                st.error("â±ï¸ ç¿»è¨³ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ3åˆ†åˆ¶é™ï¼‰")
                return False
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return False
    
    @staticmethod
    def load_database():
        """Load and return database"""
        try:
            # Ensure database directory exists
            db_path = Path('database')
            db_path.mkdir(exist_ok=True)
            
            csv_file = db_path / 'analyzed_papers.csv'
            if csv_file.exists():
                df = pd.read_csv(csv_file, encoding='utf-8')
                return df
            else:
                return pd.DataFrame()
        except Exception as e:
            st.error(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.info("ğŸ’¡ æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„")
            return pd.DataFrame()
    
    @staticmethod
    def get_database_stats():
        """Get database statistics"""
        df = WorkbenchController.load_database()
        
        if df.empty:
            return {
                "total_papers": 0,
                "categories": 0,
                "recent_papers": 0,
                "latest_date": "ãªã—"
            }
        
        stats = {
            "total_papers": len(df),
            "categories": 0,
            "recent_papers": 0,
            "latest_date": "ãªã—"
        }
        
        # Categories
        if 'ã‚«ãƒ†ã‚´ãƒª' in df.columns:
            categories = set()
            for cat_str in df['ã‚«ãƒ†ã‚´ãƒª'].dropna():
                if isinstance(cat_str, str):
                    categories.update([c.strip() for c in cat_str.split('/')])
            stats["categories"] = len(categories)
        
        # Recent papers (2025)
        if 'å…¬é–‹æ—¥' in df.columns and not df.empty:
            try:
                recent_mask = df['å…¬é–‹æ—¥'].str.startswith('2025', na=False)
                stats["recent_papers"] = recent_mask.sum()
                stats["latest_date"] = df['å…¬é–‹æ—¥'].max()
            except:
                stats["recent_papers"] = 0
                stats["latest_date"] = "ã‚¨ãƒ©ãƒ¼"
        
        return stats

def show_search_tab():
    """Search and Analysis tab"""
    st.markdown('<div class="section-card">', unsafe_allow_html=True)
    
    st.header("ğŸ“ è«–æ–‡æ¤œç´¢ãƒ»åˆ†æ")
    st.markdown("arXivã‹ã‚‰è«–æ–‡ã‚’æ¤œç´¢ã—ã¦è©³ç´°åˆ†æã‚’è¡Œã„ã¾ã™")
    
    with st.form("search_form", clear_on_submit=False):
        # Search query input
        col1, col2 = st.columns([3, 1])
        with col1:
            query = st.text_input(
                "ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                placeholder="ä¾‹: GraphRAG, æ·±å±¤å­¦ç¿’, Transformer architecture",
                help="è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã¾ãŸã¯ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯ã‚’æ—¥æœ¬èªãƒ»è‹±èªã§å…¥åŠ›"
            )
        
        # Options
        col1, col2, col3 = st.columns(3)
        with col1:
            mode = st.selectbox(
                "åˆ†æã®æ·±ã•",
                ["shallow", "moderate", "deep"],
                index=1,
                help="shallow=åŸºæœ¬æƒ…å ±ã®ã¿, moderate=æ¨™æº–åˆ†æ, deep=è©³ç´°åˆ†æï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰"
            )
        
        with col2:
            limit = st.number_input(
                "æœ€å¤§è«–æ–‡æ•°",
                min_value=1,
                max_value=50,
                value=10,
                help="åˆ†æã™ã‚‹è«–æ–‡ã®æœ€å¤§æ•°"
            )
        
        with col3:
            skip_analyzed = st.checkbox(
                "åˆ†ææ¸ˆã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—",
                value=True,
                help="æ—¢ã«åˆ†ææ¸ˆã¿ã®è«–æ–‡ã‚’é‡è¤‡å‡¦ç†ã—ãªã„"
            )
        
        # Submit button
        submitted = st.form_submit_button("ğŸš€ æ¤œç´¢é–‹å§‹", type="primary", use_container_width=True)
    
    # Execute search
    if submitted:
        # Set processing flag
        st.session_state.processing = True
        
        if WorkbenchController.execute_search(query, mode, limit, skip_analyzed):
            st.session_state.processing = False
            st.rerun()  # Refresh to show new data
        else:
            st.session_state.processing = False
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Examples section
    with st.expander("ğŸ’¡ æ¤œç´¢ä¾‹ã¨ãƒ’ãƒ³ãƒˆ"):
        st.markdown("""
        **æ¤œç´¢ä¾‹:**
        - `GraphRAG` - GraphRAGé–¢é€£è«–æ–‡
        - `æ·±å±¤å­¦ç¿’ æœ€é©åŒ–` - æ·±å±¤å­¦ç¿’ã®æœ€é©åŒ–æ‰‹æ³•
        - `large language model evaluation` - LLMã®è©•ä¾¡æ‰‹æ³•
        - `computer vision transformer` - Vision Transformeré–¢é€£
        
        **ãƒ’ãƒ³ãƒˆ:**
        - è‹±èªã§ã®æ¤œç´¢ãŒæ¨å¥¨ã•ã‚Œã¾ã™ï¼ˆè«–æ–‡ã®å¤šããŒè‹±èªã®ãŸã‚ï¼‰
        - è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™
        - åˆ†æãƒ¢ãƒ¼ãƒ‰ã¯åˆå›ã¯'moderate'ãŒãŠã™ã™ã‚ã§ã™
        - å‡¦ç†æ™‚é–“: shallow(5åˆ†) < moderate(10åˆ†) < deep(20åˆ†)
        """)

def show_database_tab():
    """Database management tab"""
    st.markdown('<div class="section-card">', unsafe_allow_html=True)
    
    st.header("ğŸ“Š è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
    
    # Load data
    df = WorkbenchController.load_database()
    stats = WorkbenchController.get_database_stats()
    
    # Stats display
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“š ç·è«–æ–‡æ•°", stats["total_papers"])
    with col2:
        st.metric("ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªæ•°", stats["categories"])
    with col3:
        st.metric("ğŸ“… 2025å¹´ã®è«–æ–‡", stats["recent_papers"])
    with col4:
        st.metric("ğŸ†• æœ€æ–°", stats["latest_date"])
    
    if df.empty:
        st.markdown('<div class="info-box">ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ã¾ã ç©ºã§ã™ã€‚ä¸Šã®ã€Œè«–æ–‡æ¤œç´¢ãƒ»åˆ†æã€ã‚¿ãƒ–ã§æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
        return
    
    # Management buttons
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        export_disabled = df.empty
        if st.button("ğŸ“¤ Excelå‡ºåŠ›", type="primary", help="å…¨ãƒ‡ãƒ¼ã‚¿ã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›" if not export_disabled else "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", disabled=export_disabled):
            filename = WorkbenchController.export_database()
            if filename and os.path.exists(filename):
                with open(filename, 'rb') as f:
                    st.download_button(
                        label="ğŸ’¾ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=f.read(),
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
    
    with col2:
        if st.button("ğŸ“ˆ çµ±è¨ˆè¡¨ç¤º", help="è©³ç´°çµ±è¨ˆã‚’è¡¨ç¤º"):
            # Show actual statistics
            with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ", expanded=True):
                if not df.empty:
                    st.subheader("åŸºæœ¬çµ±è¨ˆ")
                    col_stat1, col_stat2 = st.columns(2)
                    
                    with col_stat1:
                        st.metric("ç·è«–æ–‡æ•°", len(df))
                        
                        # Category distribution
                        if 'ã‚«ãƒ†ã‚´ãƒª' in df.columns:
                            categories = df['ã‚«ãƒ†ã‚´ãƒª'].value_counts().head(5)
                            st.write("**ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ (Top 5):**")
                            for cat, count in categories.items():
                                st.write(f"- {cat}: {count}ä»¶")
                    
                    with col_stat2:
                        # Date range
                        if 'å…¬é–‹æ—¥' in df.columns:
                            try:
                                dates = pd.to_datetime(df['å…¬é–‹æ—¥'], errors='coerce')
                                valid_dates = dates.dropna()
                                if not valid_dates.empty:
                                    st.metric("æœ€å¤ã®è«–æ–‡", valid_dates.min().strftime('%Y-%m-%d'))
                                    st.metric("æœ€æ–°ã®è«–æ–‡", valid_dates.max().strftime('%Y-%m-%d'))
                            except:
                                st.write("æ—¥ä»˜æƒ…å ±ãŒä¸æ­£ã§ã™")
                        
                        # Score distribution
                        if 'é‡è¦åº¦' in df.columns or 'relevance_score' in df.columns:
                            score_col = 'é‡è¦åº¦' if 'é‡è¦åº¦' in df.columns else 'relevance_score'
                            scores = pd.to_numeric(df[score_col], errors='coerce').dropna()
                            if not scores.empty:
                                st.metric("å¹³å‡ã‚¹ã‚³ã‚¢", f"{scores.mean():.2f}")
                else:
                    st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    with col3:
        if st.button("ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", help="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"):
            cmd = "python cli_app.py registry backup"
            with st.spinner("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸­..."):
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                if result.returncode == 0:
                    st.success("âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
                else:
                    st.error("âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼")
    
    with col4:
        if st.button("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‰Šé™¤", help="ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆæ³¨æ„ï¼‰"):
            # Use session state for confirmation dialog
            if 'confirm_delete' not in st.session_state:
                st.session_state.confirm_delete = False
            st.session_state.confirm_delete = True
    
    # Show confirmation dialog if delete button was clicked
    if 'confirm_delete' in st.session_state and st.session_state.confirm_delete:
        st.warning("âš ï¸ **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‰Šé™¤ã®ç¢ºèª**")
        st.error("ã“ã®æ“ä½œã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ã™ã¹ã¦ã®åˆ†ææ¸ˆã¿è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¾ã™ã€‚")
        
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("ğŸ—‘ï¸ å‰Šé™¤å®Ÿè¡Œ", type="primary"):
                # Execute database reset
                cmd = "python cli_app.py registry reset --force --no-backup"
                with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤ä¸­..."):
                    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                    if result.returncode == 0:
                        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        st.session_state.confirm_delete = False
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("âŒ å‰Šé™¤ã‚¨ãƒ©ãƒ¼")
                        st.text(result.stderr)
        
        with col2:
            if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                st.session_state.confirm_delete = False
                st.rerun()
    
    # Data display
    st.subheader("è«–æ–‡ä¸€è¦§")
    
    # Filters
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        search_text = st.text_input(
            "ğŸ” æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿", 
            placeholder="ã‚¿ã‚¤ãƒˆãƒ«ã€è‘—è€…ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§çµã‚Šè¾¼ã¿...",
            key="db_filter"
        )
    with col2:
        available_sort_cols = []
        for col in ['å…¬é–‹æ—¥', 'ã‚¿ã‚¤ãƒˆãƒ«', 'è‘—è€…']:
            if col in df.columns:
                available_sort_cols.append(col)
        
        if available_sort_cols:
            sort_col = st.selectbox(
                "ä¸¦ã³æ›¿ãˆ", 
                available_sort_cols, 
                key="db_sort"
            )
        else:
            sort_col = None
            st.text("ä¸¦ã³æ›¿ãˆ: ãªã—")
    with col3:
        show_count = st.selectbox("è¡¨ç¤ºæ•°", [10, 25, 50, 100], key="db_limit")
    
    # Apply filters
    filtered_df = df.copy()
    
    if search_text:
        # Search in multiple columns
        search_cols = ['ã‚¿ã‚¤ãƒˆãƒ«', 'è‘—è€…', 'ã‚«ãƒ†ã‚´ãƒª']
        available_cols = [col for col in search_cols if col in filtered_df.columns]
        
        if available_cols:
            mask = pd.Series(False, index=filtered_df.index)
            for col in available_cols:
                mask |= filtered_df[col].astype(str).str.contains(search_text, case=False, na=False)
            filtered_df = filtered_df[mask]
    
    # Sort
    if sort_col and sort_col in filtered_df.columns:
        filtered_df = filtered_df.sort_values(sort_col, ascending=False)
    
    # Display ALL 21 columns - show all available columns in database
    # First, check what columns actually exist in the dataframe
    existing_columns = list(filtered_df.columns)
    
    # Define all possible 21 columns we want to display
    all_21_columns = [
        'arxiv_id', 'ã‚¿ã‚¤ãƒˆãƒ«', 'è‘—è€…', 'å…¬é–‹æ—¥', 'å–å¾—æ—¥', 'ã‚«ãƒ†ã‚´ãƒª',
        'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'å‡¦ç†çŠ¶æ…‹', 'æ¦‚è¦JP', 'è¦ç‚¹_ä¸€è¨€', 'æ–°è¦æ€§', 
        'æ‰‹æ³•', 'å®Ÿé¨“è¨­å®š', 'çµæœ', 'è€ƒå¯Ÿ', 'ä»Šå¾Œã®èª²é¡Œ', 
        'å¿œç”¨ã‚¢ã‚¤ãƒ‡ã‚¢', 'é‡è¦åº¦', 'ãƒªãƒ³ã‚¯_pdf', 'è½åˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆURL', 'å‚™è€ƒ'
    ]
    
    # Also check for alternative column names (English or variations)
    alternative_names = {
        'title': 'ã‚¿ã‚¤ãƒˆãƒ«',
        'authors': 'è‘—è€…',
        'published_date': 'å…¬é–‹æ—¥',
        'analyzed_at': 'å–å¾—æ—¥',
        'categories': 'ã‚«ãƒ†ã‚´ãƒª',
        'keywords': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰',
        'status': 'å‡¦ç†çŠ¶æ…‹',
        'analysis_summary': 'æ¦‚è¦JP',
        'summary': 'æ¦‚è¦JP',
        'one_line_summary': 'è¦ç‚¹_ä¸€è¨€',
        'novelty': 'æ–°è¦æ€§',
        'key_findings': 'æ–°è¦æ€§',
        'methodology': 'æ‰‹æ³•',
        'method': 'æ‰‹æ³•',
        'experimental_setup': 'å®Ÿé¨“è¨­å®š',
        'validation_method': 'å®Ÿé¨“è¨­å®š',
        'results': 'çµæœ',
        'experimental_results': 'çµæœ',
        'discussion': 'è€ƒå¯Ÿ',
        'discussion_points': 'è€ƒå¯Ÿ',
        'future_work': 'ä»Šå¾Œã®èª²é¡Œ',
        'limitations': 'ä»Šå¾Œã®èª²é¡Œ',
        'application_ideas': 'å¿œç”¨ã‚¢ã‚¤ãƒ‡ã‚¢',
        'applicability': 'å¿œç”¨ã‚¢ã‚¤ãƒ‡ã‚¢',
        'importance': 'é‡è¦åº¦',
        'relevance_score': 'é‡è¦åº¦',
        'pdf_link': 'ãƒªãƒ³ã‚¯_pdf',
        'pdf_url': 'ãƒªãƒ³ã‚¯_pdf',
        'ochiai_url': 'è½åˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆURL',
        'ochiai_format_url': 'è½åˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆURL',
        'notes': 'å‚™è€ƒ',
        'memo': 'å‚™è€ƒ'
    }
    
    # Build the actual display columns
    display_cols = []
    display_names = {}  # Store display names for columns
    
    for desired_col in all_21_columns:
        # Check if column exists as-is
        if desired_col in existing_columns:
            display_cols.append(desired_col)
            display_names[desired_col] = desired_col
        else:
            # Check for alternative names
            found = False
            for alt_name, japanese_name in alternative_names.items():
                if alt_name in existing_columns and japanese_name == desired_col:
                    display_cols.append(alt_name)
                    display_names[alt_name] = desired_col
                    found = True
                    break
            
            # If still not found, add placeholder column with empty values
            if not found:
                # Add a new column with empty values for missing data
                filtered_df[desired_col] = ''
                display_cols.append(desired_col)
                display_names[desired_col] = desired_col
    
    if display_cols:
        # Prepare display dataframe with renamed columns
        display_df = filtered_df[display_cols].copy()
        
        # Rename columns to Japanese for display
        rename_dict = {}
        for col in display_cols:
            if col in display_names:
                rename_dict[col] = display_names[col]
        
        if rename_dict:
            display_df = display_df.rename(columns=rename_dict)
        
        # Ensure all 21 columns are present (reorder to match expected order)
        final_columns = []
        for col in all_21_columns:
            if col in display_df.columns:
                final_columns.append(col)
        
        # Display with horizontal scrolling for 21 columns
        st.dataframe(
            display_df[final_columns].head(show_count),
            use_container_width=True,
            height=400
        )
        
        st.info(f"ğŸ“‹ è¡¨ç¤ºä¸­: {min(show_count, len(filtered_df))} / {len(filtered_df)} ä»¶ï¼ˆç·æ•°: {len(df)}ä»¶ï¼‰| 21é …ç›®å…¨è¡¨ç¤º")
    else:
        st.error("è¡¨ç¤ºå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    st.markdown('</div>', unsafe_allow_html=True)

def show_translation_tab():
    """Translation tab"""
    st.markdown('<div class="section-card">', unsafe_allow_html=True)
    
    st.header("ğŸŒ è«–æ–‡ç¿»è¨³")
    st.markdown("arXivè«–æ–‡ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¾ã™ï¼ˆå­¦è¡“ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    
    with st.form("translation_form"):
        # Input
        col1, col2 = st.columns([3, 1])
        with col1:
            arxiv_id = st.text_input(
                "ğŸ“„ arXiv ID",
                placeholder="ä¾‹: 2409.17580v1, 2503.13804v1",
                help="ç¿»è¨³ã—ãŸã„è«–æ–‡ã®arXiv IDã‚’å…¥åŠ›ï¼ˆURLã‹ã‚‰ã§ã‚‚OKï¼‰"
            )
        
        with col2:
            academic_mode = st.checkbox(
                "å­¦è¡“ãƒ¢ãƒ¼ãƒ‰",
                value=True,
                help="å­¦è¡“çš„ãªç¿»è¨³ã‚’è¡Œã†ï¼ˆæ¨å¥¨ï¼‰"
            )
        
        # Submit
        submitted = st.form_submit_button("ğŸš€ ç¿»è¨³å®Ÿè¡Œ", type="primary", use_container_width=True)
    
    # Execute translation
    if submitted:
        # Clean up arXiv ID if URL is provided
        clean_id = arxiv_id.strip()
        if "arxiv.org/abs/" in clean_id:
            clean_id = clean_id.split("arxiv.org/abs/")[-1]
        
        if WorkbenchController.translate_paper(clean_id):
            st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Show translation history
    st.subheader("ğŸ“š ç¿»è¨³å±¥æ­´")
    
    translations_dir = Path("translations")
    if translations_dir.exists() and translations_dir.is_dir():
        translation_files = list(translations_dir.glob("*.html"))
        
        if translation_files:
            # Sort by modification time
            translation_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            for file_path in translation_files[:10]:  # Show last 10
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.text(f"ğŸ“„ {file_path.stem}")
                
                with col2:
                    mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                    st.text(f"ğŸ•’ {mod_time.strftime('%m/%d %H:%M')}")
                
                with col3:
                    if st.button("ğŸ‘€ è¡¨ç¤º", key=f"view_{file_path.stem}"):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                            
                            with st.expander(f"ç¿»è¨³å†…å®¹: {file_path.stem}", expanded=True):
                                st.markdown(content, unsafe_allow_html=True)
                        except Exception as e:
                            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        else:
            st.info("ğŸ’¡ ç¿»è¨³å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ç¿»è¨³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        st.info("ğŸ’¡ ç¿»è¨³å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

def main():
    """Main application"""
    
    # Title
    st.title("ğŸ“š arXiv Research Workbench")
    st.markdown("**è«–æ–‡æ¤œç´¢ãƒ»åˆ†æãƒ»ç¿»è¨³ã®ãŸã‚ã®çµ±åˆãƒ„ãƒ¼ãƒ«**")
    
    # First time user guidance
    stats = WorkbenchController.get_database_stats()
    if stats["total_papers"] == 0:
        st.info("ğŸ‘‹ åˆå›åˆ©ç”¨ã§ã™ã‹ï¼Ÿã€ŒğŸ” æ¤œç´¢ãƒ»åˆ†æã€ã‚¿ãƒ–ã‹ã‚‰è«–æ–‡æ¤œç´¢ã‚’å§‹ã‚ã¦ãã ã•ã„ï¼")
    
    # Tab navigation
    tab1, tab2, tab3 = st.tabs(["ğŸ” æ¤œç´¢ãƒ»åˆ†æ", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ğŸŒ ç¿»è¨³"])
    
    with tab1:
        show_search_tab()
    
    with tab2:
        show_database_tab()
    
    with tab3:
        show_translation_tab()
    
    # Sidebar info
    with st.sidebar:
        st.header("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        
        # System status with real-time info
        stats = WorkbenchController.get_database_stats()
        
        # Status indicators
        st.markdown("### ğŸ“Š ç¾åœ¨ã®çŠ¶æ³")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“š åˆ†ææ¸ˆã¿", stats["total_papers"])
        with col2:
            # Check if processing is active
            if 'processing' in st.session_state and st.session_state.processing:
                st.markdown("ğŸ”„ **å‡¦ç†ä¸­**")
            else:
                st.markdown("âœ… **å¾…æ©Ÿä¸­**")
        
        # Database health
        st.markdown("### ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
        if stats["total_papers"] > 0:
            st.success(f"æ­£å¸¸ ({stats['total_papers']}ä»¶)")
            if stats["latest_date"] != "ãªã—":
                st.caption(f"æœ€æ–°: {stats['latest_date']}")
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        # Quick actions
        st.markdown("### âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
        if st.button("ğŸ”„ ç”»é¢æ›´æ–°", key="sidebar_refresh"):
            st.rerun()
        
        if stats["total_papers"] > 0:
            if st.button("ğŸ“¤ å³åº§ã«Export", key="sidebar_export"):
                filename = WorkbenchController.export_database()
                if filename:
                    st.success("Exportå®Œäº†!")
        
        # Quick help
        with st.expander("ğŸ”§ åŸºæœ¬çš„ãªä½¿ã„æ–¹"):
            st.markdown("""
            1. **æ¤œç´¢ãƒ»åˆ†æ**ã‚¿ãƒ–ã§è«–æ–‡ã‚’æ¤œç´¢
            2. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**ã‚¿ãƒ–ã§çµæœã‚’ç¢ºèªãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            3. **ç¿»è¨³**ã‚¿ãƒ–ã§è«–æ–‡ã‚’æ—¥æœ¬èªåŒ–
            
            **åˆå›åˆ©ç”¨ã®æ–¹ã¸:**
            - æ¤œç´¢ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„
            - åˆ†æãƒ¢ãƒ¼ãƒ‰ã¯'moderate'ãŒãŠã™ã™ã‚
            - çµæœã¯Excelã§å‡ºåŠ›ã§ãã¾ã™
            """)
        
        # System info
        with st.expander("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"):
            st.markdown("""
            - **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰**: Vertex AI (Gemini)
            - **å‡¦ç†æ™‚é–“**: 40ç§’ç¨‹åº¦/è«–æ–‡
            - **å¯¾å¿œè¨€èª**: æ—¥æœ¬èªãƒ»è‹±èª
            - **å‡ºåŠ›å½¢å¼**: Excel (21åˆ—è©³ç´°)
            """)
        
        # Warning
        st.warning("âš ï¸ Vertex AIä½¿ç”¨ä¸­ï¼šå‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™")

if __name__ == "__main__":
    main()
